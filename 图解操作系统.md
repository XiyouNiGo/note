# 一、硬件结构

+ 冯诺依曼模型：中央处理器（CPU）、内存、输⼊设备、输出设备、总线。

+ 那 CPU 执⾏程序的过程如下：

  第⼀步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个

  指令数据存⼊到「指令寄存器」。

  第⼆步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执⾏；

  第三步，CPU 执⾏完指令后，「程序计数器」的值⾃增，表示指向下⼀条指令。这个⾃增的⼤⼩，由 CPU 的位宽决定，⽐如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会⾃增 4；

+ 每⼀次脉冲信号⾼低电平的转换就是⼀个周期，称为时钟周期。

+ 不同的指令需要的时钟周期是不同的。

+ 对于程序的 CPU 执⾏时间，我们可以拆解成 CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积。

+ 时钟周期时间就是我们前⾯提及的 CPU 主频。

+ 只有运算⼤数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU的计算性能相差不⼤。

+ 64 位 CPU 可以寻址更⼤的内存空间。

+ 操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位。

+ SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在。

+ DRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在
  电容⾥，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是
  DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。

+ L1 Cache 通常会分为「数据缓存」和「指令缓存」，一般为64字节。

+ L1 Cache 和L2 Cache 都是每个 CPU 核⼼独有的，⽽ L3 Cache 是多个 CPU 核⼼共享的。

+ ⽐如，有⼀个 int array[100] 的数组，当载⼊ array[0] 时，由于这个数组元素的⼤⼩在内存只占 4 字节，不⾜ 64 字节，CPU 就会顺序加载数组元素到 array[15]。

+ ⼀个内存的访问地址，包括组标记、CPU Line 索引、偏移量这三种信息。⽽对于 CPU Cache ⾥的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。

+ CPU分支预测器：如果分⽀预测可以预测到接下来要执⾏ if ⾥的指令，还是 else指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU可以直接从 Cache 读取到指令，于是执⾏速度就会很快。在 C/C++ 语⾔中编译器提供了 likely 和 unlikely 这两种宏进行分支预测。

+ 在 Linux 上提供了 sched_setaffinity ⽅法，来实现将线程绑定到某个 CPU 核⼼这⼀功能。

+ 保持内存与 Cache ⼀致性最简单的⽅式是，把数据同时写⼊内存和Cache中，这种⽅法称为写直达（Write Through）。

+ 在写回机制中，当发⽣写操作时，新的数据仅仅被写⼊ Cache Block ⾥，只有当修改过的Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率。只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，⽽在缓存命中的情况下，则在写⼊后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可。

+ 解决缓存一致性：写传播、事务的串行化。

  总线嗅探：CPU 需要每时每刻监听总线上的⼀切活动，但是不管别的核⼼的 Cache 是否缓存相同的数据，都需要发出⼀个⼴播事件。

  MESI（Modified、Exclusive、Shared、Invalidate）协议基于总线嗅探机制实现了事务串形化。

+ 因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象称为伪共享（False Sharing）。解决：通过__cacheline_aligned_in_smp设置Cache Line对齐地址、内存填充。

+ Linux中任务优先级的数值越⼩，优先级越⾼。

+ 在CFS算法调度的时候，会优先选择vruntime少的任务。在计算虚拟运⾏时间vruntime还要考虑普通任务的权重值。

  nice级别越低，权重值就越⼤，vruntime权重越小，优先被调度。nice 值并不是表示优先级，⽽是表示优先级的修

  正数值，priority(new) = priority(old) + nice。nice 调整的是普通任务的优先级，所以不管怎么缩⼩ nice 值，任务永远都是普通任务。

  每个 CPU 都有⾃⼰的运⾏队列（Run Queue, rq），⽤于描述在此 CPU 上所运⾏的所有进程，其队列包含三个运⾏队列，Deadline 运⾏队列 dl_rq、实时任务运⾏队列 rt_rq和 CFS 运⾏队列 csf_rq，其中 csf_rq 是⽤红⿊树来描述的，按 vruntime ⼤⼩来排序的，最左侧的叶⼦节点，就是下次会被调度的任务。这⼏种调度类是有优先级的，优先级如下：Deadline > Realtime > Fair，因此实时任务总是会⽐普通任务优先被执⾏。普通任务的调度类是 Fail，由 CFS 调度器来进⾏管理。

+ 中断请求的响应程序，也就是中断处理程序，要尽可能快的执⾏完，这样可以减少对正常进程运⾏调度地影响。所以Linux中中断处理分为上半部和下半部。软中断是以内核线程的⽅式执⾏的。每个 CPU 核⼼都对应着⼀个内核线程ksoftirqd。

# 二、操作系统结构

+ SMP 的意思是**对称多处理**，代表着每个 CPU 的地位是相等的，对资源的使⽤权限也是相同的，多个 CPU 共享同⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源。
+ Window的内核设计是混合型内核，Linux的内核设计是宏内核，华为的鸿蒙操作系统的内核架构是微内核。

# 三、内存管理

+ 单⽚机的 CPU 是直接操作内存的「物理地址」。

+ 内存分段和内存分⻚：

  + 内存分段：

    + 分段机制下的虚拟地址由两部分组成，**段选择⼦**和**段内偏移量**。
    + **段选择⼦**就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是**段号**，⽤作段表的索引。**段表**⾥⾯保存的是这个**段的基地址、段的界限和特权等级**等。
    + 不足：内存碎片（外部碎片）、内存交换的效率低（linuxswap）。

  + 内存分页：

    + 分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。

    + 当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个**缺⻚异常**，进⼊系统内核空间分配物理内存（struct page）、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

    + 只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。

    + 在分⻚机制下，虚拟地址分为两部分，⻚号和⻚内偏移。⻚号作为⻚表的索引，⻚表包含物理⻚每⻚所在物理内存的基地址。

    + 多级页表：

      如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。

  + 段⻚式内存管理（内存分段 + 内存分页）：

    + 先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚。
    + 地址结构就由**段号、段内⻚号和⻚内位移**三部分组成。

+ TLB：

  TLB（*Translation Lookaside Buffer*） ，通常称为⻚表缓存、转址旁路缓存、快表等。

+ 文件映射段（堆、栈之间）：

  包括动态库、共享内存等，从低地址开始向上增长。

  mmap可以在文件映射段动态分配内存。

# 四、进程与线程





