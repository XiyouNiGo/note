# 一、硬件结构

+ 冯诺依曼模型：中央处理器（CPU）、内存、输⼊设备、输出设备、总线。

+ 那 CPU 执⾏程序的过程如下：

  第⼀步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个

  指令数据存⼊到「指令寄存器」。

  第⼆步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执⾏；

  第三步，CPU 执⾏完指令后，「程序计数器」的值⾃增，表示指向下⼀条指令。这个⾃增的⼤⼩，由 CPU 的位宽决定，⽐如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会⾃增 4；

+ 每⼀次脉冲信号⾼低电平的转换就是⼀个周期，称为时钟周期。

+ 不同的指令需要的时钟周期是不同的。

+ 对于程序的 CPU 执⾏时间，我们可以拆解成 CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积。

+ 时钟周期时间就是我们前⾯提及的 CPU 主频。

+ 只有运算⼤数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU的计算性能相差不⼤。

+ 64 位 CPU 可以寻址更⼤的内存空间。

+ 操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位。

+ SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在。

+ DRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在
  电容⾥，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是
  DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。

+ L1 Cache 通常会分为「数据缓存」和「指令缓存」，一般为64字节。

+ L1 Cache 和L2 Cache 都是每个 CPU 核⼼独有的，⽽ L3 Cache 是多个 CPU 核⼼共享的。

+ ⽐如，有⼀个 int array[100] 的数组，当载⼊ array[0] 时，由于这个数组元素的⼤⼩在内存只占 4 字节，不⾜ 64 字节，CPU 就会顺序加载数组元素到 array[15]。

+ ⼀个内存的访问地址，包括组标记、CPU Line 索引、偏移量这三种信息。⽽对于 CPU Cache ⾥的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。

+ CPU分支预测器：如果分⽀预测可以预测到接下来要执⾏ if ⾥的指令，还是 else指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU可以直接从 Cache 读取到指令，于是执⾏速度就会很快。在 C/C++ 语⾔中编译器提供了 likely 和 unlikely 这两种宏进行分支预测。

+ 在 Linux 上提供了 sched_setaffinity ⽅法，来实现将线程绑定到某个 CPU 核⼼这⼀功能。

+ 保持内存与 Cache ⼀致性最简单的⽅式是，把数据同时写⼊内存和Cache中，这种⽅法称为写直达（Write Through）。

+ 在写回机制中，当发⽣写操作时，新的数据仅仅被写⼊ Cache Block ⾥，只有当修改过的Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率。只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，⽽在缓存命中的情况下，则在写⼊后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可。

+ 解决缓存一致性：写传播、事务的串行化。

  总线嗅探：CPU 需要每时每刻监听总线上的⼀切活动，但是不管别的核⼼的 Cache 是否缓存相同的数据，都需要发出⼀个⼴播事件。

  MESI（Modified、Exclusive、Shared、Invalidate）协议基于总线嗅探机制实现了事务串形化。

+ 因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象称为伪共享（False Sharing）。解决：通过__cacheline_aligned_in_smp设置Cache Line对齐地址、内存填充。

+ Linux中任务优先级的数值越⼩，优先级越⾼。

+ 在CFS算法调度的时候，会优先选择vruntime少的任务。在计算虚拟运⾏时间vruntime还要考虑普通任务的权重值。

  nice级别越低，权重值就越⼤，vruntime权重越小，优先被调度。nice 值并不是表示优先级，⽽是表示优先级的修

  正数值，priority(new) = priority(old) + nice。nice 调整的是普通任务的优先级，所以不管怎么缩⼩ nice 值，任务永远都是普通任务。

  每个 CPU 都有⾃⼰的运⾏队列（Run Queue, rq），⽤于描述在此 CPU 上所运⾏的所有进程，其队列包含三个运⾏队列，Deadline 运⾏队列 dl_rq、实时任务运⾏队列 rt_rq和 CFS 运⾏队列 csf_rq，其中 csf_rq 是⽤红⿊树来描述的，按 vruntime ⼤⼩来排序的，最左侧的叶⼦节点，就是下次会被调度的任务。这⼏种调度类是有优先级的，优先级如下：Deadline > Realtime > Fair，因此实时任务总是会⽐普通任务优先被执⾏。普通任务的调度类是 Fail，由 CFS 调度器来进⾏管理。

+ 中断请求的响应程序，也就是中断处理程序，要尽可能快的执⾏完，这样可以减少对正常进程运⾏调度地影响。所以Linux中中断处理分为上半部和下半部。软中断是以内核线程的⽅式执⾏的。每个 CPU 核⼼都对应着⼀个内核线程ksoftirqd。

# 二、操作系统结构

+ SMP 的意思是**对称多处理**，代表着每个 CPU 的地位是相等的，对资源的使⽤权限也是相同的，多个 CPU 共享同⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源。
+ Window的内核设计是混合型内核，Linux的内核设计是宏内核，华为的鸿蒙操作系统的内核架构是微内核。

# 三、内存管理

+ 单⽚机的 CPU 是直接操作内存的「物理地址」。

+ 内存分段和内存分⻚：

  + 内存分段：

    + 分段机制下的虚拟地址由两部分组成，**段选择⼦**和**段内偏移量**。
    + **段选择⼦**就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是**段号**，⽤作段表的索引。**段表**⾥⾯保存的是这个**段的基地址、段的界限和特权等级**等。
    + 不足：内存碎片（外部碎片）、内存交换的效率低（linuxswap）。

  + 内存分页：

    + 分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。

    + 当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个**缺⻚异常**，进⼊系统内核空间分配物理内存（struct page）、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

    + 只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。

    + 在分⻚机制下，虚拟地址分为两部分，⻚号和⻚内偏移。⻚号作为⻚表的索引，⻚表包含物理⻚每⻚所在物理内存的基地址。

    + 多级页表：

      如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。

  + 段⻚式内存管理（内存分段 + 内存分页）：

    + 先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚。
    + 地址结构就由**段号、段内⻚号和⻚内位移**三部分组成。

+ TLB：

  TLB（*Translation Lookaside Buffer*） ，通常称为⻚表缓存、转址旁路缓存、快表等。

+ 文件映射段（堆、栈之间）：

  包括动态库、共享内存等，从低地址开始向上增长。

  mmap可以在文件映射段动态分配内存。

# 四、进程与线程

+ 挂起状态：

  + 描述进程没有占⽤实际的物理内存空间的情况（物理内存空间换出到硬盘），这个状态就是挂起状态。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的返回（占用物理内存空间）。

  + 挂起状态可以分为两种：

    阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；

    就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏。

![image-20210522213942175](C:\Users\NiGo\AppData\Roaming\Typora\typora-user-images\image-20210522213942175.png)

+ PCB：
  + 在操作系统中，是⽤**进程控制块**（*process control block*，*PCB*）数据结构来描述进程的。
  + 通常是通过**链表**的⽅式进⾏组织，把具有**相同状态的进程链在⼀起，组成各种队列**。如就绪队列、阻塞队列。

+ CPU 上下⽂切换：

  + CPU 上下⽂切换分成：进程上下⽂切换、线程上下⽂切换和中断上下⽂切换。
  + 进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。
  + 当两个线程不是属于同⼀个进程，则线程上下文切换的过程就跟进程上下⽂切换⼀样。

+ 用户线程：

  + ⽤户线程的优点：
    + 每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统；
    + ⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，所以速度特别快。
  + ⽤户线程的缺点：
    + 由于操作系统不参与线程的调度，如果⼀个线程发起了系统调⽤⽽阻塞，那进程所包含的⽤户线程都不能执⾏。
    + 当⼀个线程开始运⾏后，除⾮它主动地交出 CPU 的使⽤权，否则它所在的进程当中的其他线程⽆法运⾏，因为⽤户态的线程没法打断当前运⾏中的线程，它没有这个特权，只有操作系统才有，但是⽤户线程不是由操作系统管理的。
    + 由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢。

+ 内核线程：

  + 内核线程的优点：
    + 在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏；
    + 分配给线程，多线程的进程获得更多的 CPU 运⾏时间；
  + 内核线程的缺点：
    + 在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和TCB；
    + 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；

+ 

  

+ LWP：
  + 轻量级进程 (LWP, light weight process) 是一种由**内核支持的用户线程**。它是**基于内核线程的高级抽象**，因此只有先支持内核线程，才能有 LWP 。每一个LWP可以支持一个或多个用户线程，每个 LWP 由一个内核线程支持。内核线程与LWP之间的模型实际上就是《操作系统概念》上所提到的一对一线程模型。在这种实现的操作系统中， LWP 相当于用户线程。 由于每个 LWP 都与一个特定的内核线程关联，因此每个 LWP 都是一个独立的线程调度单元。即使有一个 LWP 在系统调用中阻塞，也不会影响整个进程的执行。
  + Linux下使用进程模拟的线程（难怪gettid返回值类型是pid_t）。

+ pid、tid：

  + tid实际上是内核（线程）中可调度对象的标识符，而pid是共享内存和fds（进程）的可调度对象组的标识符。
  + 当一个进程只有一个线程时，pid和tid总是相同的。

+ 五种调度原则：

  + CPU 利⽤率：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率；
  + 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
  + 周转时间：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好；
  + 等待时间：这个等待时间不是阻塞状态的时间，⽽是进程处于就绪队列的时间，等待的时间越⻓，⽤户越不满意；
  + 响应时间：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

+ ⾼响应⽐优先调度算法：

  每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏，「响应⽐优先级」的计算公式：优先级 = (等待时间 + 要求服务时间) / 要求服务时间。

+ 匿名管道是特殊的⽂件，只存在于内存，不存于⽂件系统中。

+ 消息队列：

  + **消息队列是保存在内核中的消息链表**，在发送数据时，会分成⼀个⼀个独⽴的数据单元，也就是消息体（数据块）。
  + 消息体是⽤户⾃定义的数据类型，消息的发送⽅和接收⽅要约定好消息体的数据类型，所以**每个消息体都是固定⼤⼩的存储块**，不像管道是⽆格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。
  + 消息队列⽣命周期随内核，匿名管道随进程。
  + 不足：
    + **消息队列不适合⽐较⼤数据的传输**，在 Linux 内核中，会有两个宏定义MSGMAX 和 MSGMNB ，它们以字节为单位，分别定义了⼀条消息的最⼤⻓度和⼀个队列的最⼤⻓度。
    + **消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销**。

+ 共享内存：

  共享内存的机制，就是拿出⼀块虚拟地址空间来，映射到相同的物理内存中。

+ i + 1：

  从内存取出i值后，放入到寄存器；对寄存器中的i值+1；把寄存器中的i值放回内存。

+ 哲学家就餐：

  + 方案一：信号量

    可能死锁，所有哲学家同时拿左手的刀叉。

  + 方案二：信号量 + 互斥锁

    效率低。

  + 方案三：信号量 + 偶数先拿左、奇数先拿右

    避免死锁。

  + 方案四：信号量 + 互斥锁 + state数组

    ⼀个哲学家只有在两个邻居都没有进餐时，才可以进⼊进餐状态。

# 五、调度算法

+ LRU：

  在每次访问内存时都必须要更新「整个链表」（主要在寻找已分配的页），开销大。

+ 时钟⻚⾯置换算法：

  把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。

+ 磁盘调度算法：

  + 寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省⼀些不必要的寻道时间，从⽽提⾼磁盘的访问性能。

  + 最短寻道时间优先：

    可能存在某些请求的**饥饿**。

  + 扫描算法：

    + 磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法。

    + 不足：

      中间部分的磁道会⽐较占便宜，中间部分相⽐其他部分响应的频率会⽐较多，也就是说每个磁道的响应频率存在差异。

  + 循环扫描算法：

    循环扫描算法相⽐于扫描算法，对于各个位置磁道响应频率相对⽐较平均。

  + LOOK 与 C-LOOK算法：

    

